"""
데이터 수집기 - yfinance 기반 (pykrx 호환성 문제 해결)
"""

import asyncio
import aiohttp
from datetime import date, datetime, timedelta
from typing import List, Optional, Dict
import pandas as pd
import os
import re

from engine.config import SignalConfig
from engine.models import StockData, ChartData, SupplyData, NewsItem

# 주요 한국 주식 리스트 (File generated by fetch_stock_list.py)
try:
    from engine.stock_list_data import KR_TOP_STOCKS
except ImportError:
    # Fallback if file not found
    print("Warning: stock_list_data.py not found. Using fallback list.")
    KR_TOP_STOCKS = [
        ("005930.KS", "삼성전자", "KOSPI"),
        ("000660.KS", "SK하이닉스", "KOSPI"),
        ("373220.KS", "LG에너지솔루션", "KOSPI"),
        ("207940.KS", "삼성바이오로직스", "KOSPI"),
        ("005380.KS", "현대차", "KOSPI"),
        ("005490.KS", "POSCO홀딩스", "KOSPI"),
        ("035420.KS", "NAVER", "KOSPI"),
        ("000270.KS", "기아", "KOSPI"),
        ("247540.KQ", "에코프로비엠", "KOSDAQ"),
        ("086520.KQ", "에코프로", "KOSDAQ"),
    ]


class KRXCollector:
    """KRX 데이터 수집기 (yfinance 기반)"""
    
    def __init__(self, config: SignalConfig = None):
        self.config = config or SignalConfig()
        self._session = None
    
    async def __aenter__(self):
        timeout = aiohttp.ClientTimeout(total=600)
        self._session = aiohttp.ClientSession(timeout=timeout)
        return self
    
    async def __aexit__(self, exc_type, exc_val, exc_tb):
        if self._session:
            await self._session.close()
    
    async def get_top_gainers(self, market: str, top_n: int = 30) -> List[StockData]:
        """상승률 상위 종목 조회 (yfinance 기반)"""
        try:
            import yfinance as yf
            
            result = []
            
            # 시장별 필터링
            stocks_to_check = [s for s in KR_TOP_STOCKS if s[2] == market]
            
            for ticker, name, mkt in stocks_to_check:
                try:
                    stock = yf.Ticker(ticker)
                    hist = stock.history(period="5d")
                    
                    if hist.empty or len(hist) < 2:
                        continue
                    
                    close = float(hist['Close'].iloc[-1])
                    prev_close = float(hist['Close'].iloc[-2])
                    volume = int(hist['Volume'].iloc[-1])
                    
                    if prev_close <= 0:
                        continue
                    
                    change_pct = ((close - prev_close) / prev_close) * 100
                    trading_value = close * volume
                    
                    # 필터링
                    if trading_value < self.config.min_trading_value:
                        continue
                    if change_pct < self.config.min_change_pct or change_pct > self.config.max_change_pct:
                        continue
                    
                    # 제외 키워드 체크
                    if any(kw in name for kw in self.config.exclude_keywords):
                        continue
                    
                    code = ticker.replace(".KS", "").replace(".KQ", "")
                    
                    result.append(StockData(
                        code=code,
                        name=name,
                        market=mkt,
                        sector="",
                        close=close,
                        change_pct=round(change_pct, 2),
                        volume=volume,
                        trading_value=int(trading_value),
                        marcap=0,
                    ))
                    
                except Exception as e:
                    continue
            
            # 등락률 정렬
            result.sort(key=lambda x: x.change_pct, reverse=True)
            
            return result[:top_n]
            
        except Exception as e:
            print(f"[KRX] 상승률 조회 오류: {e}")
            return []
    
    async def get_stock_detail(self, code: str) -> Optional[StockData]:
        """종목 상세 정보 조회"""
        try:
            import yfinance as yf
            
            # 코드 변환
            ticker = f"{code}.KS" if len(code) == 6 else code
            
            stock = yf.Ticker(ticker)
            info = stock.info
            hist = stock.history(period="1y")
            
            high_52w = float(hist['High'].max()) if not hist.empty else 0
            
            return StockData(
                code=code,
                name=info.get('longName', info.get('shortName', code)),
                market="",
                high_52w=high_52w
            )
        except Exception as e:
            print(f"[KRX] 상세 정보 조회 오류 ({code}): {e}")
            return None
    
    async def get_chart_data(self, code: str, days: int = 60) -> List[ChartData]:
        """차트 데이터 조회"""
        try:
            import yfinance as yf
            
            ticker = f"{code}.KS" if len(code) == 6 and not code.endswith(('.KS', '.KQ')) else code
            
            stock = yf.Ticker(ticker)
            hist = stock.history(period="3mo")
            
            if hist.empty:
                # KOSDAQ 티커로 재시도
                ticker = f"{code}.KQ"
                stock = yf.Ticker(ticker)
                hist = stock.history(period="3mo")
            
            if hist.empty:
                return []
            
            result = []
            for idx, row in hist.tail(days).iterrows():
                result.append(ChartData(
                    date=idx.date() if hasattr(idx, 'date') else idx,
                    open=float(row['Open']),
                    high=float(row['High']),
                    low=float(row['Low']),
                    close=float(row['Close']),
                    volume=int(row['Volume'])
                ))
            
            return result
            
        except Exception as e:
            print(f"[KRX] 차트 데이터 조회 오류 ({code}): {e}")
            return []
    
    async def get_supply_data(self, code: str) -> Optional[SupplyData]:
        """수급 데이터 조회 (yfinance는 수급 미지원, 기본값 반환)"""
        # yfinance는 외국인/기관 수급 데이터를 제공하지 않음
        # 기본값 반환
        return SupplyData(
            code=code,
            foreign_buy_5d=0,
            foreign_buy_20d=0,
            inst_buy_5d=0,
            inst_buy_20d=0,
        )


class EnhancedNewsCollector:
    """향상된 뉴스 수집기 (네이버 금융)"""
    
    MAJOR_SOURCES = {
        "한국경제": 0.9,
        "매일경제": 0.9,
        "머니투데이": 0.85,
        "서울경제": 0.85,
        "이데일리": 0.85,
        "연합뉴스": 0.85,
        "뉴스1": 0.8,
        "헤럴드경제": 0.8,
        "아시아경제": 0.8,
    }
    
    def __init__(self, config: SignalConfig = None):
        self.config = config or SignalConfig()
        self._session = None
    
    async def __aenter__(self):
        timeout = aiohttp.ClientTimeout(total=600)
        self._session = aiohttp.ClientSession(timeout=timeout)
        return self
    
    async def __aexit__(self, exc_type, exc_val, exc_tb):
        if self._session:
            await self._session.close()
    
    async def get_stock_news(self, code: str, limit: int = 5, stock_name: str = "") -> List[NewsItem]:
        """종목 관련 뉴스 수집 (네이버 금융 뉴스 iframe)"""
        try:
            from bs4 import BeautifulSoup
            
            # 코드 정리
            code_num = ''.join(filter(str.isdigit, code))
            if len(code_num) < 6:
                code_num = code_num.zfill(6)
            
            # 1. 뉴스 컨테이너 페이지 호출 (세션/쿠키 웜업)
            container_url = f"https://finance.naver.com/item/news.naver?code={code_num}"
            headers = {
                "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36",
            }
            
            # 컨테이너 호출은 생략해도 될 수 있으나, Referer 설정 및 쿠키 확보를 위해 수행
            async with self._session.get(container_url, headers=headers) as response:
                if response.status != 200:
                    return []
                # 컨테이너 내용은 굳이 파싱하지 않음 (iframe ID=news_frame을 찾을 수도 있으나 직접 URL 구성이 빠름)
            
            # 2. 실제 뉴스 목록 URL 구성 (중요: page=1, sm=title_entity_id.basic)
            # iframe src: /item/news_news.naver?code=...&page=&sm=...&clusterId=
            # 위에서 page가 비어있으면 데이터가 안나오는 경우가 있음 (No data)
            target_url = f"https://finance.naver.com/item/news_news.naver?code={code_num}&page=1&sm=title_entity_id.basic"
            
            # Referer 추가 (중요)
            sub_headers = headers.copy()
            sub_headers['Referer'] = container_url
            
            news_list = []
            
            async with self._session.get(target_url, headers=sub_headers) as sub_res:
                if sub_res.status == 200:
                    sub_html = ""
                    try:
                        # iframe 내부(news_news.naver)는 주로 EUC-KR
                        sub_html = await sub_res.text(encoding='euc-kr', errors='replace')
                    except:
                        # 실패시 UTF-8 시도
                        try:
                            sub_html = await sub_res.text(encoding='utf-8', errors='replace')
                        except:
                            sub_html = await sub_res.text(errors='replace')
                            
                    sub_soup = BeautifulSoup(sub_html, 'html.parser')
                    
                    # iframe 내부(news_news.naver) 테이블 파싱
                    rows = sub_soup.select('table.type5 tbody tr')
                    
                    for tr in rows:
                        try:
                            # 제목이 없는 row (구분선이나 no_data) 건너뛰기
                            title_tag = tr.select_one('td.title a')
                            if not title_tag: continue
                            
                            title = title_tag.get_text(strip=True)
                            link = title_tag.get('href', '')
                            
                            info_tag = tr.select_one('td.info')
                            source = info_tag.get_text(strip=True) if info_tag else ""
                            
                            reliability = self.MAJOR_SOURCES.get(source, 0.5)
                            
                            # 중복 체크
                            is_duplicate = False
                            for existing in news_list:
                                if existing.title == title:
                                    is_duplicate = True
                                    break
                            
                            if is_duplicate:
                                continue
                            
                            news_list.append(NewsItem(
                                title=title,
                                summary="",
                                source=source,
                                url=f"https://finance.naver.com{link}" if link.startswith('/') else link,
                                reliability=reliability,
                            ))
                            
                            if len(news_list) >= limit:
                                break
                        except:
                            continue
            
            return news_list
                
        except Exception as e:
            print(f"[News] 뉴스 수집 오류 ({code}): {e}")
            return []
    
    async def get_news_content(self, url: str) -> str:
        """뉴스 본문 크롤링"""
        try:
            from bs4 import BeautifulSoup
            
            headers = {
                "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36"
            }
            
            async with self._session.get(url, headers=headers) as response:
                if response.status != 200:
                    return ""
                
                try:
                    html = await response.text(encoding='euc-kr', errors='replace')
                except:
                    html = await response.text()
                    
                soup = BeautifulSoup(html, 'html.parser')
                
                # 네이버 금융 뉴스 본문
                content_div = soup.select_one('div.news_content')
                if content_div:
                    return content_div.get_text(strip=True)[:500]
                
                return ""
                
        except Exception as e:
            return ""
